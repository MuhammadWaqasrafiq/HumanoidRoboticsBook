"use strict";(globalThis.webpackChunkai_book=globalThis.webpackChunkai_book||[]).push([[5997],{6143:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/HumanoidRoboticsBook/docs/why-physical-ai/","label":"1. Why Physical AI Is the Next Frontier","docId":"why-physical-ai/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/intro","label":"Tutorial Intro","docId":"intro","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/hardware-needed/","label":"2. The Hardware You Actually Need","docId":"hardware-needed/index","unlisted":false},{"type":"category","label":"Tutorial - Basics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/create-a-page","label":"Create a Page","docId":"tutorial-basics/create-a-page","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/create-a-document","label":"Create a Document","docId":"tutorial-basics/create-a-document","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/create-a-blog-post","label":"Create a Blog Post","docId":"tutorial-basics/create-a-blog-post","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/markdown-features","label":"Markdown Features","docId":"tutorial-basics/markdown-features","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/deploy-your-site","label":"Deploy your site","docId":"tutorial-basics/deploy-your-site","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-basics/congratulations","label":"Congratulations!","docId":"tutorial-basics/congratulations","unlisted":false}],"href":"/HumanoidRoboticsBook/docs/category/tutorial---basics"},{"type":"link","href":"/HumanoidRoboticsBook/docs/ros-2-nervous-system/","label":"3. ROS 2 \u2013 The Robotic Nervous System","docId":"ros-2-nervous-system/index","unlisted":false},{"type":"category","label":"Tutorial - Extras","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-extras/manage-docs-versions","label":"Manage Docs Versions","docId":"tutorial-extras/manage-docs-versions","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/tutorial-extras/translate-your-site","label":"Translate your site","docId":"tutorial-extras/translate-your-site","unlisted":false}],"href":"/HumanoidRoboticsBook/docs/category/tutorial---extras"},{"type":"link","href":"/HumanoidRoboticsBook/docs/urdf-digital-twins/","label":"4. URDF & Digital Twins","docId":"urdf-digital-twins/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/simulators-showdown/","label":"5. Simulators Showdown","docId":"simulators-showdown/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/isaac-platform-deep-dive/","label":"6. NVIDIA Isaac Platform Deep Dive","docId":"isaac-platform-deep-dive/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/perception-stack/","label":"7. Perception Stack \u2013 VSLAM, Depth, Segmentation","docId":"perception-stack/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/bipedal-locomotion/","label":"8. Bipedal Locomotion and Balance Control","docId":"bipedal-locomotion/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/dexterous-manipulation/","label":"9. Dexterous Manipulation with Humanoid Hands","docId":"dexterous-manipulation/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/vla-models/","label":"10. Vision-Language-Action Models (VLA)","docId":"vla-models/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/voice-to-action/","label":"11. Voice-to-Action Pipeline","docId":"voice-to-action/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/sim-to-real/","label":"12. Sim-to-Real Transfer Cookbook","docId":"sim-to-real/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/capstone-project/","label":"13. Capstone Project \u2013 Autonomous Humanoid Butler","docId":"capstone-project/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/appendix-a-lab-builds/","label":"Appendix A: Lab Build Guides","docId":"appendix-a-lab-builds/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/appendix-b-troubleshooting/","label":"Appendix B: Troubleshooting Bible","docId":"appendix-b-troubleshooting/index","unlisted":false},{"type":"link","href":"/HumanoidRoboticsBook/docs/appendix-c-future-roadmap/","label":"Appendix C: Future Roadmap","docId":"appendix-c-future-roadmap/index","unlisted":false}]},"docs":{"appendix-a-lab-builds/index":{"id":"appendix-a-lab-builds/index","title":"Appendix A: Lab Build Guides","description":"This appendix provides detailed guides for building various physical AI lab setups, ranging from budget-friendly options to high-performance configurations. Each guide includes a comprehensive Bill of Materials (BOM), assembly instructions, and initial setup procedures.","sidebar":"tutorialSidebar"},"appendix-b-troubleshooting/index":{"id":"appendix-b-troubleshooting/index","title":"Appendix B: Troubleshooting Bible","description":"title Troubleshooting Bible\\"","sidebar":"tutorialSidebar"},"appendix-c-future-roadmap/index":{"id":"appendix-c-future-roadmap/index","title":"Appendix C: Future Roadmap","description":"This appendix outlines the potential future directions and enhancements for the Physical AI and Humanoid Robotics ecosystem. It covers emerging technologies, advanced research topics, and community contributions that can extend the concepts presented in this book.","sidebar":"tutorialSidebar"},"bipedal-locomotion/index":{"id":"bipedal-locomotion/index","title":"8. Bipedal Locomotion and Balance Control","description":"This chapter focuses on the complex challenges and cutting-edge solutions for bipedal locomotion and balance control in humanoid robots. We will explore the theoretical foundations and practical implementations that allow robots to walk, run, and maintain stability.","sidebar":"tutorialSidebar"},"capstone-project/index":{"id":"capstone-project/index","title":"13. Capstone Project \u2013 Autonomous Humanoid Butler","description":"This capstone project brings together all the concepts and technologies explored in the book to build an \\"Autonomous Humanoid Butler.\\" This chapter will guide you through the process of integrating the perception, locomotion, manipulation, and voice-to-action pipeline into a single, cohesive system.","sidebar":"tutorialSidebar"},"dexterous-manipulation/index":{"id":"dexterous-manipulation/index","title":"9. Dexterous Manipulation with Humanoid Hands","description":"This chapter delves into the intricate world of dexterous manipulation, focusing on how humanoid robots interact with objects using their hands. We will cover the design of robotic hands, sensor integration, and control strategies for complex grasping and in-hand manipulation tasks.","sidebar":"tutorialSidebar"},"hardware-needed/index":{"id":"hardware-needed/index","title":"2. The Hardware You Actually Need","description":"Building intelligent robots requires a careful selection of hardware. In this chapter, we demystify the components you\'ll need, from the development workstation to the robot itself. Our focus is on accessible, high-performance hardware that provides the best value for learning and prototyping in 2025-2026.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes.","sidebar":"tutorialSidebar"},"isaac-platform-deep-dive/index":{"id":"isaac-platform-deep-dive/index","title":"6. NVIDIA Isaac Platform Deep Dive","description":"The NVIDIA Isaac platform is a comprehensive robotics development ecosystem that accelerates the creation, simulation, and deployment of AI-powered robots. At its core is NVIDIA Isaac Sim, built on the Omniverse platform, which provides a high-fidelity, physically accurate simulation environment.","sidebar":"tutorialSidebar"},"perception-stack/index":{"id":"perception-stack/index","title":"7. Perception Stack \u2013 VSLAM, Depth, Segmentation","description":"This chapter will delve into the critical role of the perception stack in physical AI and humanoid robotics. We will explore key technologies such as Visual Simultaneous Localization and Mapping (VSLAM), depth sensing, and semantic segmentation, understanding how robots perceive and interpret their environment.","sidebar":"tutorialSidebar"},"ros-2-nervous-system/index":{"id":"ros-2-nervous-system/index","title":"3. ROS 2 \u2013 The Robotic Nervous System","description":"If a robot\'s hardware is its body, the Robot Operating System (ROS) is its central nervous system. It\'s the framework that allows different parts of the robot\u2014sensors, actuators, and decision-making algorithms\u2014to communicate with each other in a standardized, robust, and scalable way.","sidebar":"tutorialSidebar"},"sim-to-real/index":{"id":"sim-to-real/index","title":"12. Sim-to-Real Transfer Cookbook","description":"This chapter provides a practical \\"cookbook\\" for effectively transferring policies and models trained in simulation to real-world humanoid robots. Sim-to-real transfer is a critical step in robotics development, allowing for rapid iteration and safe experimentation in virtual environments before deployment on physical hardware.","sidebar":"tutorialSidebar"},"simulators-showdown/index":{"id":"simulators-showdown/index","title":"5. Simulators Showdown","description":"A realistic physics simulator is a critical tool for modern robotics development. It allows for rapid prototyping, safe testing of control algorithms, and generation of synthetic data for training AI models. In the ROS ecosystem, several powerful simulators are available. This chapter compares the leading contenders and explains our choice for this book.","sidebar":"tutorialSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template.","sidebar":"tutorialSidebar"},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed...","sidebar":"tutorialSidebar"},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:","sidebar":"tutorialSidebar"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:","sidebar":"tutorialSidebar"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack).","sidebar":"tutorialSidebar"},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features.","sidebar":"tutorialSidebar"},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs.","sidebar":"tutorialSidebar"},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French.","sidebar":"tutorialSidebar"},"urdf-digital-twins/index":{"id":"urdf-digital-twins/index","title":"4. URDF & Digital Twins","description":"Before a robot can exist in simulation or the real world, it must first be described in a way a computer can understand. This is the role of the Unified Robot Description Format (URDF).","sidebar":"tutorialSidebar"},"vla-models/index":{"id":"vla-models/index","title":"10. Vision-Language-Action Models (VLA)","description":"This chapter introduces Vision-Language-Action (VLA) models, a new paradigm in AI that integrates visual perception, natural language understanding, and robotic control. VLAs enable robots to comprehend high-level commands and perform complex tasks in unstructured environments.","sidebar":"tutorialSidebar"},"voice-to-action/index":{"id":"voice-to-action/index","title":"11. Voice-to-Action Pipeline","description":"This chapter details the construction of a complete voice-to-action pipeline, enabling humanoid robots to respond to spoken natural language commands. We will integrate components for speech recognition, natural language understanding, task planning, and robot control.","sidebar":"tutorialSidebar"},"why-physical-ai/index":{"id":"why-physical-ai/index","title":"1. Why Physical AI Is the Next Frontier","description":"For the past decade, the world of Artificial Intelligence has been dominated by purely digital applications. Large Language Models (LLMs) have mastered text, and diffusion models have conquered the visual arts. Yet, this intelligence has been confined to the silicon realm.","sidebar":"tutorialSidebar"}}}}')}}]);