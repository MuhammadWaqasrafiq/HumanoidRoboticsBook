"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_book=self.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[6991],{8453:(n,e,r)=>{r.d(e,{R:()=>o,x:()=>a});var i=r(6540);const s={},t=i.createContext(s);function o(n){const e=i.useContext(t);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),i.createElement(t.Provider,{value:e},n.children)}},8506:(n,e,r)=>{r.r(e),r.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"dexterous-manipulation/index","title":"Chapter 09: Dexterous Manipulation","description":"Master grasp planning, inverse kinematics, force control, and multi-fingered hand manipulation for humanoid robots","source":"@site/docs/dexterous-manipulation/index.mdx","sourceDirName":"dexterous-manipulation","slug":"/dexterous-manipulation/","permalink":"/HumanoidRoboticsBook/docs/dexterous-manipulation/","draft":false,"unlisted":false,"editUrl":"https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook/tree/main/docs/dexterous-manipulation/index.mdx","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"title":"Chapter 09: Dexterous Manipulation","description":"Master grasp planning, inverse kinematics, force control, and multi-fingered hand manipulation for humanoid robots"},"sidebar":"tutorialSidebar","previous":{"title":"08. Bipedal Locomotion","permalink":"/HumanoidRoboticsBook/docs/bipedal-locomotion/"},"next":{"title":"10. Vision-Language-Action Models","permalink":"/HumanoidRoboticsBook/docs/vla-models/"}}');var s=r(4848),t=r(8453);const o={sidebar_position:9,title:"Chapter 09: Dexterous Manipulation",description:"Master grasp planning, inverse kinematics, force control, and multi-fingered hand manipulation for humanoid robots"},a="Chapter 09: Dexterous Manipulation",l={},c=[{value:"Introduction",id:"introduction",level:2},{value:"9.1 Grasp Planning Fundamentals",id:"91-grasp-planning-fundamentals",level:2},{value:"9.1.1 Grasp Quality Metrics",id:"911-grasp-quality-metrics",level:3},{value:"9.1.2 Grasp Synthesis Methods",id:"912-grasp-synthesis-methods",level:3},{value:"9.2 Inverse Kinematics (IK)",id:"92-inverse-kinematics-ik",level:2},{value:"9.2.1 Problem Formulation",id:"921-problem-formulation",level:3},{value:"9.2.2 Analytic IK (Closed-Form)",id:"922-analytic-ik-closed-form",level:3},{value:"9.2.3 Numerical IK (Iterative)",id:"923-numerical-ik-iterative",level:3},{value:"9.2.4 Optimization-Based IK",id:"924-optimization-based-ik",level:3},{value:"9.2.5 Production IK: TRAC-IK",id:"925-production-ik-trac-ik",level:3},{value:"9.3 Force and Impedance Control",id:"93-force-and-impedance-control",level:2},{value:"9.3.1 Hybrid Position/Force Control",id:"931-hybrid-positionforce-control",level:3},{value:"9.3.2 Impedance Control",id:"932-impedance-control",level:3},{value:"9.3.3 Force/Torque Sensing",id:"933-forcetorque-sensing",level:3},{value:"9.4 Multi-Fingered Hands",id:"94-multi-fingered-hands",level:2},{value:"9.4.1 Hand Platforms",id:"941-hand-platforms",level:3},{value:"9.4.2 Grasp Execution with Multi-Fingered Hands",id:"942-grasp-execution-with-multi-fingered-hands",level:3},{value:"9.4.3 In-Hand Manipulation",id:"943-in-hand-manipulation",level:3},{value:"9.5 Object Manipulation Pipeline",id:"95-object-manipulation-pipeline",level:2},{value:"9.5.1 Complete Pick-and-Place",id:"951-complete-pick-and-place",level:3},{value:"9.5.2 Failure Recovery",id:"952-failure-recovery",level:3},{value:"9.6 Advanced Topics",id:"96-advanced-topics",level:2},{value:"9.6.1 Dual-Arm Coordination",id:"961-dual-arm-coordination",level:3},{value:"9.6.2 Tool Use",id:"962-tool-use",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",mermaid:"mermaid",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"chapter-09-dexterous-manipulation",children:"Chapter 09: Dexterous Manipulation"})}),"\n",(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(e.p,{children:"Dexterous manipulation is the ability to skillfully interact with objects using robotic hands and arms. While locomotion gets a humanoid from point A to B, manipulation enables it to perform useful tasks: opening doors, picking packages, assembling components, or pouring drinks. This chapter covers the complete manipulation stack from grasp planning to force-controlled execution."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"What You'll Learn:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Grasp planning algorithms (force closure, quality metrics)"}),"\n",(0,s.jsx)(e.li,{children:"Inverse kinematics solvers (analytic, numerical, optimization-based)"}),"\n",(0,s.jsx)(e.li,{children:"Force/impedance control for compliant interaction"}),"\n",(0,s.jsx)(e.li,{children:"Multi-fingered hand control strategies"}),"\n",(0,s.jsx)(e.li,{children:"Object manipulation pipelines"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Prerequisites:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Chapter 04 (ROS 2 fundamentals)"}),"\n",(0,s.jsx)(e.li,{children:"Chapter 05 (URDF and forward kinematics)"}),"\n",(0,s.jsx)(e.li,{children:"Chapter 07 (perception for object detection)"}),"\n",(0,s.jsx)(e.li,{children:"Basic linear algebra and robotics kinematics"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"91-grasp-planning-fundamentals",children:"9.1 Grasp Planning Fundamentals"}),"\n",(0,s.jsx)(e.h3,{id:"911-grasp-quality-metrics",children:"9.1.1 Grasp Quality Metrics"}),"\n",(0,s.jsx)(e.p,{children:'A grasp is "good" if it resists external forces and achieves the task goal. We quantify this with quality metrics:'}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Force Closure"}),": A grasp achieves force closure if it can apply wrenches (force + torque) in all directions on the object. Mathematically:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Grasp matrix G: 6\xd7n (n = number of contacts)\nForce closure \u27fa rank(G) = 6 AND wrench space spans \u211d\u2076\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Form Closure"}),": Stricter condition - the grasp prevents any object motion even without friction. Requires 7+ contacts for general 3D objects."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Grasp Quality Indices:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Largest Minimum Wrench (LMW)"}),": Maximum disturbance the grasp can resist"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Volume of Grasp Wrench Space"}),": Larger = more robust"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Distance to Force Closure Boundary"}),": Safety margin"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Task-specific metrics"}),": Alignment with manipulation goal (e.g., torque capacity for twisting a lid)"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Ferrari-Canny Metric"})," (most common):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def ferrari_canny_metric(contact_points, contact_normals, friction_coeff=0.7):\n    """\n    Compute grasp quality as radius of largest ball inscribed in convex hull\n    of grasp wrench space (normalized by object size).\n\n    Higher = more robust grasp\n    """\n    G = build_grasp_matrix(contact_points, contact_normals, friction_coeff)\n    wrench_space = compute_wrench_space(G)  # Convex hull in 6D\n    quality = min_distance_to_boundary(wrench_space)  # Ball radius\n    return quality / object_radius  # Normalized\n'})}),"\n",(0,s.jsx)(e.h3,{id:"912-grasp-synthesis-methods",children:"9.1.2 Grasp Synthesis Methods"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Analytic Approaches:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Antipodal Grasps"}),": Two-finger grasps with contact normals opposing through object center of mass"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Force Closure Test"}),": Check if contact forces span 6D wrench space"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Parallel-Jaw Optimization"}),": Find best finger positions for gripper"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Sampling-Based Approaches:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Generate candidate grasps (e.g., sample points on object mesh)"}),"\n",(0,s.jsx)(e.li,{children:"Evaluate quality metric for each"}),"\n",(0,s.jsx)(e.li,{children:"Rank and return top-k grasps"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example: Antipodal Grasp Generation"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef generate_antipodal_grasps(point_cloud, normals, gripper_width=0.08):\n    \"\"\"\n    Find antipodal grasp candidates on object point cloud.\n\n    Args:\n        point_cloud: Nx3 array of surface points\n        normals: Nx3 array of surface normals\n        gripper_width: Maximum gripper opening (meters)\n\n    Returns:\n        grasps: List of (point1, point2, approach_axis, quality) tuples\n    \"\"\"\n    grasps = []\n\n    for i, p1 in enumerate(point_cloud):\n        n1 = normals[i]\n\n        # Find points on opposite side within gripper width\n        distances = cdist([p1], point_cloud)[0]\n        candidates = np.where((distances &gt; 0.02) & (distances &lt; gripper_width))[0]\n\n        for j in candidates:\n            p2 = point_cloud[j]\n            n2 = normals[j]\n\n            # Check antipodal condition: normals oppose through CoM\n            grasp_axis = (p2 - p1) / np.linalg.norm(p2 - p1)\n\n            # Normals should be ~opposite and aligned with grasp axis\n            alignment1 = np.dot(n1, grasp_axis)\n            alignment2 = np.dot(n2, -grasp_axis)\n\n            if alignment1 &gt; 0.95 and alignment2 &gt; 0.95:  # ~5\xb0 tolerance\n                # Compute grasp quality (simplified Ferrari-Canny)\n                quality = min(alignment1, alignment2) * (1 - distances[j] / gripper_width)\n\n                grasps.append({\n                    'p1': p1,\n                    'p2': p2,\n                    'axis': grasp_axis,\n                    'width': distances[j],\n                    'quality': quality\n                })\n\n    # Return top 10 grasps\n    grasps.sort(key=lambda g: g['quality'], reverse=True)\n    return grasps[:10]\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Learning-Based Approaches:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"GraspNet"}),": Neural network predicts grasp quality from RGB-D images"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Contact-GraspNet"}),": Predicts contact points and approach directions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"DexNet"}),": Large-scale dataset (millions of grasps) for training"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"92-inverse-kinematics-ik",children:"9.2 Inverse Kinematics (IK)"}),"\n",(0,s.jsxs)(e.p,{children:["Inverse kinematics solves: ",(0,s.jsx)(e.strong,{children:"Given desired end-effector pose, find joint angles to achieve it."})]}),"\n",(0,s.jsx)(e.h3,{id:"921-problem-formulation",children:"9.2.1 Problem Formulation"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Forward Kinematics: \u03b8 \u2192 X\n   \u03b8 \u2208 \u211d\u207f (joint angles) \u2192 X \u2208 SE(3) (end-effector pose)\n\nInverse Kinematics: X \u2192 \u03b8\n   X (desired pose) \u2192 \u03b8 (joint angles to achieve it)\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Challenges:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Non-unique"}),": Redundant robots (7+ DOF arms) have infinite solutions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"No closed-form"}),": Most robots require numerical methods"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Singularities"}),": Jacobian rank drops, losing DOFs"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint limits"}),": Solutions must satisfy physical constraints"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"922-analytic-ik-closed-form",children:"9.2.2 Analytic IK (Closed-Form)"}),"\n",(0,s.jsx)(e.p,{children:"For specific robot geometries (e.g., 6-DOF arms with spherical wrist), closed-form solutions exist."}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Example: 6-DOF Anthropomorphic Arm"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def analytic_ik_6dof(target_pose, shoulder_offset, elbow_offset, wrist_offset):\n    """\n    Analytic IK for 6-DOF arm with spherical wrist (Puma-like).\n\n    Returns: List of up to 8 solutions (joint angle sets)\n    """\n    x, y, z = target_pose.translation\n    R = target_pose.rotation\n\n    # Decouple position (first 3 joints) and orientation (wrist joints)\n    wrist_center = target_pose.translation - wrist_offset * R[:, 2]  # Z-axis\n\n    # Solve for shoulder/elbow (2R chain in plane)\n    r = np.sqrt(wrist_center[0]**2 + wrist_center[1]**2)\n    z_offset = wrist_center[2] - shoulder_offset[2]\n\n    # Law of cosines for elbow angle\n    d = np.sqrt(r**2 + z_offset**2)\n    cos_elbow = (d**2 - elbow_offset**2 - wrist_offset**2) / (2 * elbow_offset * wrist_offset)\n\n    if abs(cos_elbow) &gt; 1:\n        return []  # Target unreachable\n\n    theta2_solutions = [np.arccos(cos_elbow), -np.arccos(cos_elbow)]  # Elbow up/down\n\n    solutions = []\n    for theta2 in theta2_solutions:\n        # Solve theta1 (shoulder pan)\n        theta1 = np.arctan2(wrist_center[1], wrist_center[0])\n\n        # ... (solve wrist angles from R, ~20 more lines)\n        # Returns 8 solutions for different arm configurations\n\n    return solutions\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Pros"}),": Fast (microseconds), exact\n",(0,s.jsx)(e.strong,{children:"Cons"}),": Robot-specific, doesn't exist for all geometries"]}),"\n",(0,s.jsx)(e.h3,{id:"923-numerical-ik-iterative",children:"9.2.3 Numerical IK (Iterative)"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Jacobian-Based Newton-Raphson:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Iterate: \u03b8_{k+1} = \u03b8_k + J\u207a(\u03b8_k) \xb7 \u0394X\n\nWhere:\n  J\u207a = pseudoinverse of Jacobian (6\xd7n matrix)\n  \u0394X = target pose - current pose (6D twist)\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Implementation with Damped Least Squares"})," (avoids singularities):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def numerical_ik_damped_ls(robot, target_pose, q_init, max_iter=100, tol=1e-4):\n    """\n    Numerical IK using Damped Least Squares (Levenberg-Marquardt).\n\n    Args:\n        robot: URDF robot model with forward kinematics\n        target_pose: SE(3) desired end-effector pose\n        q_init: Initial joint angles guess\n        lambda_damping: Damping factor (0.01-0.1)\n\n    Returns:\n        q_solution: Joint angles achieving target (or best effort)\n    """\n    q = q_init.copy()\n    lambda_damp = 0.05\n\n    for iteration in range(max_iter):\n        # Compute current pose and error\n        current_pose = robot.forward_kinematics(q)\n        pos_error = target_pose.translation - current_pose.translation\n        rot_error = rotation_error(target_pose.rotation, current_pose.rotation)  # Axis-angle\n\n        error = np.concatenate([pos_error, rot_error])  # 6D error\n\n        if np.linalg.norm(error) &lt; tol:\n            return q  # Converged\n\n        # Compute Jacobian at current config\n        J = robot.compute_jacobian(q)  # 6\xd7n\n\n        # Damped least squares update\n        JtJ = J.T @ J\n        delta_q = np.linalg.solve(JtJ + lambda_damp * np.eye(len(q)), J.T @ error)\n\n        q += delta_q\n\n        # Enforce joint limits\n        q = np.clip(q, robot.joint_limits_lower, robot.joint_limits_upper)\n\n    print(f"IK did not converge after {max_iter} iterations (error: {np.linalg.norm(error):.4f}m)")\n    return q  # Best effort\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Pros"}),": Works for any robot, handles redundancy\n",(0,s.jsx)(e.strong,{children:"Cons"}),": Slower (milliseconds), may not converge, local minima"]}),"\n",(0,s.jsx)(e.h3,{id:"924-optimization-based-ik",children:"9.2.4 Optimization-Based IK"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Formulate as constrained optimization:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"import casadi as ca\n\ndef optimization_ik(robot, target_pose, q_init, weights={'position': 100, 'orientation': 10}):\n    \"\"\"\n    IK via nonlinear optimization (IPOPT solver).\n\n    Objective: Minimize pose error + secondary objectives (joint limits, singularities)\n    \"\"\"\n    opti = ca.Opti()\n\n    q = opti.variable(robot.n_joints)  # Decision variables\n\n    # Constraint: Forward kinematics\n    current_pose = robot.fk_symbolic(q)  # CasADi symbolic expression\n\n    # Objective: Minimize pose error\n    pos_error = ca.sumsqr(current_pose[:3] - target_pose.translation)\n    rot_error = ca.sumsqr(rotation_matrix_to_axis_angle(current_pose[3:]) - target_pose.rotation_aa)\n\n    objective = weights['position'] * pos_error + weights['orientation'] * rot_error\n\n    # Secondary objective: Stay close to home position (avoid joint limits)\n    objective += 0.1 * ca.sumsqr(q - robot.home_position)\n\n    opti.minimize(objective)\n\n    # Constraints: Joint limits\n    opti.subject_to(opti.bounded(robot.q_min, q, robot.q_max))\n\n    # Solve\n    opti.solver('ipopt', {'print_time': False, 'ipopt.print_level': 0})\n    opti.set_initial(q, q_init)\n\n    try:\n        sol = opti.solve()\n        return sol.value(q)\n    except:\n        return opti.debug.value(q)  # Return best effort if no solution\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Pros"}),": Handles constraints (obstacles, joint limits), secondary objectives\n",(0,s.jsx)(e.strong,{children:"Cons"}),": Slower (10-100ms), requires optimization library"]}),"\n",(0,s.jsx)(e.h3,{id:"925-production-ik-trac-ik",children:"9.2.5 Production IK: TRAC-IK"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"TRAC-IK"})," (TracLabs Inverse Kinematics) combines speed and reliability:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Runs numerical IK and nonlinear optimization in parallel"}),"\n",(0,s.jsx)(e.li,{children:"Returns fastest solution"}),"\n",(0,s.jsx)(e.li,{children:"Widely used in ROS 2 MoveIt 2"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"# Install TRAC-IK\nsudo apt install ros-iron-trac-ik-kinematics-plugin\n\n# Configure in MoveIt 2\n# config/kinematics.yaml:\nright_arm:\n  kinematics_solver: trac_ik_kinematics_plugin/TRAC_IKKinematicsPlugin\n  kinematics_solver_timeout: 0.05  # 50ms\n  kinematics_solver_attempts: 3\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"93-force-and-impedance-control",children:"9.3 Force and Impedance Control"}),"\n",(0,s.jsxs)(e.p,{children:["Position control alone is brittle - contact with environment causes high forces and failures. ",(0,s.jsx)(e.strong,{children:"Force control"})," regulates interaction forces for safe, compliant manipulation."]}),"\n",(0,s.jsx)(e.h3,{id:"931-hybrid-positionforce-control",children:"9.3.1 Hybrid Position/Force Control"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Concept"}),": Control position in free directions, force in constrained directions."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Example: Wiping a table\n  - XY plane: Position control (move along surface)\n  - Z axis: Force control (maintain 5N downward pressure)\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Implementation:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class HybridController:\n    def __init__(self, robot, selection_matrix):\n        """\n        Hybrid position/force controller.\n\n        Args:\n            selection_matrix: 6\xd76 diagonal, 1 = force control, 0 = position control\n        """\n        self.S = selection_matrix  # Force selection\n        self.P = np.eye(6) - selection_matrix  # Position selection\n\n        self.Kp_pos = np.diag([500, 500, 500, 50, 50, 50])  # Position gains\n        self.Kp_force = np.diag([0.1, 0.1, 0.1, 0.01, 0.01, 0.01])  # Force gains\n\n    def compute_control(self, x_desired, f_desired, x_current, f_current):\n        """\n        Returns: Joint torques achieving hybrid control objective.\n        """\n        # Position error in free directions\n        x_error = x_desired - x_current\n        u_pos = self.Kp_pos @ (self.P @ x_error)\n\n        # Force error in constrained directions\n        f_error = f_desired - f_current\n        u_force = self.Kp_force @ (self.S @ f_error)\n\n        # Combined control (in task space)\n        u_task = u_pos + u_force\n\n        # Map to joint torques via Jacobian transpose\n        J = self.robot.compute_jacobian(q_current)\n        tau = J.T @ u_task\n\n        return tau\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Selection Matrix Example (Table Wiping):"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"S = np.diag([0, 0, 1, 0, 0, 0])  # Force control in Z only\n# XY position controlled, Z force controlled\n"})}),"\n",(0,s.jsx)(e.h3,{id:"932-impedance-control",children:"9.3.2 Impedance Control"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Impedance control"})," makes the robot behave like a spring-damper system:"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"F = K \xb7 (x - x_desired) + D \xb7 (\u1e8b - \u1e8b_desired)\n\nLow K \u2192 Compliant (soft)\nHigh K \u2192 Stiff (position control)\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Cartesian Impedance Controller:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'class CartesianImpedanceController:\n    def __init__(self, stiffness, damping):\n        """\n        Args:\n            stiffness: 6\xd76 diagonal (N/m for position, Nm/rad for orientation)\n            damping: 6\xd76 diagonal (critically damped: D = 2\u221a(M\xb7K))\n        """\n        self.K = stiffness  # e.g., diag([300, 300, 300, 30, 30, 30])\n        self.D = damping    # e.g., diag([50, 50, 50, 5, 5, 5])\n\n    def compute_control(self, x_desired, x_current, v_current, f_external):\n        """\n        Computes joint torques for compliant behavior.\n\n        Args:\n            f_external: Measured external forces (from F/T sensor)\n        """\n        # Task-space impedance\n        x_error = x_desired - x_current\n        f_desired = self.K @ x_error - self.D @ v_current\n\n        # Compensate for measured external forces\n        f_control = f_desired - f_external\n\n        # Map to joint torques\n        J = self.robot.compute_jacobian(q_current)\n        tau = J.T @ f_control\n\n        # Add gravity compensation\n        tau += self.robot.inverse_dynamics(q_current, zero_velocity, zero_accel)\n\n        return tau\n'})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Tuning Impedance Parameters:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Stiff"})," (K=1000): Precise positioning (pick small objects)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Compliant"})," (K=50): Safe contact (human handover, exploration)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Variable"}),": Adapt based on task (stiff in free space, soft at contact)"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Variable stiffness based on contact\nif force_sensor.norm() &gt; 2.0:  # Contact detected\n    K = np.diag([50, 50, 100, 10, 10, 10])  # Compliant in XY, stiffer in Z\nelse:\n    K = np.diag([1000, 1000, 1000, 100, 100, 100])  # Stiff in free space\n"})}),"\n",(0,s.jsx)(e.h3,{id:"933-forcetorque-sensing",children:"9.3.3 Force/Torque Sensing"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Hardware Requirements:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"6-axis F/T sensor"})," at wrist (measures Fx, Fy, Fz, Tx, Ty, Tz)"]}),"\n",(0,s.jsx)(e.li,{children:"Typical specs: \xb1200N force, \xb120Nm torque, 1000Hz sampling"}),"\n",(0,s.jsx)(e.li,{children:"Examples: ATI Mini45, Robotiq FT-300, OnRobot HEX-E"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"ROS 2 Integration:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from geometry_msgs.msg import WrenchStamped\n\nclass ForceTorqueSensor(Node):\n    def __init__(self):\n        super().__init__(\'ft_sensor\')\n\n        self.ft_sub = self.create_subscription(\n            WrenchStamped,\n            \'/ft_sensor/wrench\',\n            self.ft_callback,\n            10\n        )\n\n        self.current_wrench = np.zeros(6)\n        self.bias = np.zeros(6)  # Tare offset\n\n    def ft_callback(self, msg):\n        wrench = np.array([\n            msg.wrench.force.x,\n            msg.wrench.force.y,\n            msg.wrench.force.z,\n            msg.wrench.torque.x,\n            msg.wrench.torque.y,\n            msg.wrench.torque.z\n        ])\n\n        self.current_wrench = wrench - self.bias\n\n    def tare(self):\n        """Zero sensor (subtract gravity/tool weight)"""\n        self.bias = self.current_wrench.copy()\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"94-multi-fingered-hands",children:"9.4 Multi-Fingered Hands"}),"\n",(0,s.jsx)(e.h3,{id:"941-hand-platforms",children:"9.4.1 Hand Platforms"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Allegro Hand"})," (16 DOF, 4 fingers):"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Torque-controlled, dexterous manipulation"}),"\n",(0,s.jsx)(e.li,{children:"$10k-15k, research/education"}),"\n",(0,s.jsxs)(e.li,{children:["ROS 2 support: ",(0,s.jsx)(e.code,{children:"ros2 launch allegro_hand allegro_hand.launch.py"})]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Shadow Dexterous Hand"})," (20-24 DOF):"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Human-like kinematics, tactile sensors"}),"\n",(0,s.jsx)(e.li,{children:"$100k+, high-end research"}),"\n",(0,s.jsx)(e.li,{children:"Air muscle or electric actuation"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Barrett Hand"})," (4 DOF, 3 fingers):"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Underactuated, adaptive grasping"}),"\n",(0,s.jsx)(e.li,{children:"$25k, industrial reliability"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Robotiq 2F-85/2F-140"})," (Parallel-jaw grippers):"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Simple, robust, $5k-10k"}),"\n",(0,s.jsx)(e.li,{children:"Force control, object detection"}),"\n",(0,s.jsx)(e.li,{children:"Best for pick-and-place tasks"}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"942-grasp-execution-with-multi-fingered-hands",children:"9.4.2 Grasp Execution with Multi-Fingered Hands"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Synergy-Based Control"}),': Reduce 16+ DOF to 2-3 "grasp synergies" (coordinated motions):']}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Principal grasp synergies (from human hand studies)\nsynergy_1 = [1, 0.8, 0.6, 0.4] * 4  # Flexion (all fingers close)\nsynergy_2 = [1, -1, 0, 0] * 4       # Precision (thumb-index opposition)\nsynergy_3 = [1, 1, -1, -1] * 4      # Lateral (thumb-pinky grasp)\n\ndef execute_grasp(object_size, grasp_type='power'):\n    \"\"\"\n    Map high-level grasp command to 16 joint angles.\n    \"\"\"\n    if grasp_type == 'power':\n        # Power grasp: 100% synergy 1\n        q_target = synergy_1 * (object_size / max_aperture)\n    elif grasp_type == 'precision':\n        # Precision: 70% syn1 + 30% syn2\n        q_target = 0.7 * synergy_1 + 0.3 * synergy_2\n\n    # Send position commands to hand\n    hand.set_joint_positions(q_target)\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Tactile Feedback"})," (if available):"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def grasp_with_tactile_feedback(object_pose):\n    """\n    Close fingers until tactile contact, then apply holding force.\n    """\n    hand.move_to_pre_grasp(object_pose)\n\n    # Close fingers slowly\n    for aperture in np.linspace(max_aperture, 0, 50):\n        hand.set_aperture(aperture)\n        time.sleep(0.02)\n\n        # Check tactile sensors\n        if np.any(hand.get_tactile_readings() &gt; contact_threshold):\n            break  # Contact detected\n\n    # Apply holding force (force control)\n    hand.set_force_target(10.0)  # 10N per finger\n'})}),"\n",(0,s.jsx)(e.h3,{id:"943-in-hand-manipulation",children:"9.4.3 In-Hand Manipulation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Task"}),": Reorient object within hand (e.g., rotate screwdriver)."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Approaches:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Finger Gaiting"}),": Sequentially release/regrasp fingers"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Rolling"}),": Controlled sliding along finger surfaces"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Pivoting"}),": Rotate around fixed contact point"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Simple Pivot Controller:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def pivot_object(target_angle, pivot_finger=0):\n    """\n    Rotate object by pivoting around one finger.\n\n    Args:\n        target_angle: Desired rotation (radians)\n        pivot_finger: Index of finger to keep fixed\n    """\n    # Keep pivot finger stationary\n    hand.set_finger_stiffness(pivot_finger, stiffness=1000)\n\n    # Other fingers push tangentially\n    for i in range(4):\n        if i != pivot_finger:\n            # Compute tangential push direction\n            contact_point = hand.get_fingertip_pose(i)\n            push_direction = compute_tangent(contact_point, pivot_point, target_angle)\n\n            hand.set_finger_force(i, push_direction * 5.0)  # 5N push\n\n    # Monitor object pose, stop when target reached\n    while abs(object.get_orientation() - target_angle) &gt; 0.05:\n        time.sleep(0.01)\n\n    hand.set_all_finger_forces(0)  # Stop\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"95-object-manipulation-pipeline",children:"9.5 Object Manipulation Pipeline"}),"\n",(0,s.jsx)(e.h3,{id:"951-complete-pick-and-place",children:"9.5.1 Complete Pick-and-Place"}),"\n",(0,s.jsx)(e.mermaid,{value:"graph TD\n    A[Perceive Object] --\x3e|YOLOv8 + Depth| B[Segment & Localize]\n    B --\x3e C[Generate Grasp Candidates]\n    C --\x3e D[Rank Grasps by Quality]\n    D --\x3e E[Compute IK for Best Grasp]\n    E --\x3e|IK Feasible?| F{Success?}\n    F --\x3e|Yes| G[Move to Pre-Grasp]\n    F --\x3e|No| D\n    G --\x3e H[Approach Object]\n    H --\x3e I[Close Gripper]\n    I --\x3e J{Object Grasped?}\n    J --\x3e|Force &gt; threshold| K[Lift Object]\n    J --\x3e|No force| C\n    K --\x3e L[Move to Place Pose]\n    L --\x3e M[Open Gripper]\n    M --\x3e N[Retract]"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"ROS 2 Action Server:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from manipulation_interfaces.action import PickAndPlace\n\nclass PickAndPlaceServer(Node):\n    def __init__(self):\n        super().__init__(\'pick_place_server\')\n\n        self._action_server = ActionServer(\n            self,\n            PickAndPlace,\n            \'pick_and_place\',\n            self.execute_callback\n        )\n\n        # Components\n        self.grasp_planner = GraspPlanner()\n        self.ik_solver = TRAC_IK()\n        self.motion_planner = MoveIt2Interface()\n        self.gripper = GripperController()\n\n    def execute_callback(self, goal_handle):\n        """Execute pick-and-place task"""\n        feedback_msg = PickAndPlace.Feedback()\n\n        # 1. Perceive object\n        feedback_msg.status = "Perceiving object..."\n        goal_handle.publish_feedback(feedback_msg)\n\n        object_pose = self.perceive_object(goal_handle.request.object_id)\n\n        # 2. Plan grasp\n        feedback_msg.status = "Planning grasp..."\n        goal_handle.publish_feedback(feedback_msg)\n\n        grasps = self.grasp_planner.generate_grasps(object_pose)\n\n        # 3. Find feasible grasp (IK check)\n        for grasp in grasps:\n            q_grasp = self.ik_solver.solve(grasp.pose)\n\n            if q_grasp is not None:\n                # 4. Motion planning\n                trajectory = self.motion_planner.plan_to_pose(q_grasp)\n\n                if trajectory.success:\n                    # 5. Execute pick\n                    feedback_msg.status = "Executing pick..."\n                    goal_handle.publish_feedback(feedback_msg)\n\n                    self.execute_pick(trajectory, grasp)\n\n                    # 6. Move to place\n                    feedback_msg.status = "Moving to place pose..."\n                    goal_handle.publish_feedback(feedback_msg)\n\n                    place_traj = self.motion_planner.plan_to_pose(goal_handle.request.place_pose)\n                    self.motion_planner.execute(place_traj)\n\n                    # 7. Release\n                    self.gripper.open()\n\n                    goal_handle.succeed()\n\n                    result = PickAndPlace.Result()\n                    result.success = True\n                    return result\n\n        # No feasible grasp found\n        goal_handle.abort()\n        result = PickAndPlace.Result()\n        result.success = False\n        result.error = "No feasible grasp found"\n        return result\n'})}),"\n",(0,s.jsx)(e.h3,{id:"952-failure-recovery",children:"9.5.2 Failure Recovery"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Common Failures:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Grasp failure"})," (object slips)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"IK failure"})," (target unreachable)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Collision"})," (obstacle in path)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Perception failure"})," (object not detected)"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Recovery Strategies:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def execute_pick_with_retry(object_pose, max_attempts=3):\n    for attempt in range(max_attempts):\n        try:\n            # Attempt pick\n            success = pick_object(object_pose)\n\n            if success:\n                return True\n\n            # Failure detected - diagnose\n            if not gripper.has_object():\n                # Grasp failure - try next best grasp\n                print(f"Grasp failed, attempt {attempt+1}/{max_attempts}")\n                continue\n\n        except IKError:\n            # Try different arm configuration\n            print("IK failed, trying different seed...")\n            q_seed = sample_alternative_config()\n            continue\n\n        except CollisionError as e:\n            # Replan with obstacle avoidance\n            print(f"Collision detected: {e.obstacle_id}")\n            add_obstacle_to_scene(e.obstacle_id)\n            continue\n\n    return False  # All attempts failed\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"96-advanced-topics",children:"9.6 Advanced Topics"}),"\n",(0,s.jsx)(e.h3,{id:"961-dual-arm-coordination",children:"9.6.1 Dual-Arm Coordination"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Bimanual manipulation"}),": Two arms work together (e.g., opening a jar, folding cloth)."]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Relative Jacobian Approach:"})}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'def dual_arm_coordination(left_target, right_target, relative_constraint):\n    """\n    Coordinate two arms with relative constraint (e.g., maintain object pose).\n\n    Args:\n        relative_constraint: SE(3) transform from left to right gripper\n    """\n    # Stack arm Jacobians\n    J_left = robot.compute_jacobian(q_left, \'left_gripper\')\n    J_right = robot.compute_jacobian(q_right, \'right_gripper\')\n\n    J_dual = np.vstack([J_left, J_right])  # 12\xd714 (2 arms \xd7 7 DOF)\n\n    # Desired task-space velocities\n    v_left = Kp * (left_target - left_current)\n    v_right = Kp * (right_target - right_current)\n\n    v_task = np.concatenate([v_left, v_right])  # 12D\n\n    # Add relative constraint (e.g., maintain object orientation)\n    J_rel = compute_relative_jacobian(J_left, J_right)\n    v_rel = Kp_rel * relative_constraint_error\n\n    # Solve augmented system\n    J_augmented = np.vstack([J_dual, J_rel])\n    v_augmented = np.concatenate([v_task, v_rel])\n\n    dq = np.linalg.pinv(J_augmented) @ v_augmented  # 14D joint velocities\n\n    return dq[:7], dq[7:]  # Left and right joint velocities\n'})}),"\n",(0,s.jsx)(e.h3,{id:"962-tool-use",children:"9.6.2 Tool Use"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Task"}),": Use a tool (e.g., hammer, screwdriver) to extend manipulation capabilities."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Approach"}),": Recompute kinematics with tool as new end-effector."]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"# Original FK: base \u2192 wrist\nT_base_wrist = robot.forward_kinematics(q)\n\n# Tool transform: wrist \u2192 tool tip\nT_wrist_tool = np.array([\n    [1, 0, 0, 0.0],\n    [0, 1, 0, 0.0],\n    [0, 0, 1, 0.3],  # Tool length: 30cm\n    [0, 0, 0, 1]\n])\n\n# New FK: base \u2192 tool tip\nT_base_tool = T_base_wrist @ T_wrist_tool\n\n# IK now solves for tool tip pose (instead of wrist)\nq_solution = ik_solver.solve(T_base_tool, tool_transform=T_wrist_tool)\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Key Takeaways:"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Grasp Planning"}),": Ferrari-Canny metric balances quality vs speed; antipodal grasps work for 80% of objects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"IK Solvers"}),": Use TRAC-IK for speed + reliability; numerical methods handle redundancy"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Force Control"}),": Impedance control (K=50-300 N/m) enables safe, compliant manipulation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Multi-Fingered Hands"}),": Synergy-based control reduces complexity; tactile feedback improves robustness"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Production Pipeline"}),": Perception \u2192 Grasp Planning \u2192 IK \u2192 Motion Planning \u2192 Force-Controlled Execution"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Recommended Stack:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Perception"}),": YOLOv8 + SAM 2 (Chapter 07)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Grasp Planning"}),": GraspNet or antipodal sampling"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"IK"}),": TRAC-IK (ROS 2 MoveIt 2)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Motion Planning"}),": MoveIt 2 OMPL"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Control"}),": Cartesian impedance (K=100-300)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Gripper"}),": Robotiq 2F-85 (simple) or Allegro Hand (dexterous)"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Next Steps:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Implement grasp planner from code example (",(0,s.jsx)(e.code,{children:"grasp_planner.py"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Test IK solver on your robot URDF"}),"\n",(0,s.jsx)(e.li,{children:"Set up F/T sensor and tune impedance controller"}),"\n",(0,s.jsx)(e.li,{children:"Integrate with Chapter 07 perception for autonomous pick-and-place"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Performance Targets:"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Grasp planning: <500ms (antipodal), <2s (GraspNet)"}),"\n",(0,s.jsx)(e.li,{children:"IK solve: <50ms (TRAC-IK)"}),"\n",(0,s.jsx)(e.li,{children:"Grasp success rate: >85% (known objects), >60% (novel objects)"}),"\n",(0,s.jsx)(e.li,{children:"Force control bandwidth: >100Hz"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Books"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.em,{children:"Robotics: Modelling, Planning and Control"})," by Siciliano et al. (Chapters 3, 9-11)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.em,{children:"A Mathematical Introduction to Robotic Manipulation"})," by Murray, Li, Sastry (grasp theory)"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Papers"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:'Ferrari & Canny (1992): "Planning Optimal Grasps" (Ferrari-Canny metric)'}),"\n",(0,s.jsx)(e.li,{children:'Hogan (1985): "Impedance Control" (foundational impedance control paper)'}),"\n",(0,s.jsx)(e.li,{children:'Raibert & Craig (1981): "Hybrid Position/Force Control"'}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Packages"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"moveit2"}),": Motion planning and IK"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"trac_ik"}),": Fast, reliable IK solver"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"ros2_control"}),": Real-time joint/Cartesian control"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robotiq_2f_gripper"}),": Robotiq gripper driver"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Datasets"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"GraspNet-1Billion"}),": 1B grasp poses for training"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"YCB Object Set"}),": Standard manipulation benchmark objects"]}),"\n"]}),"\n"]}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);