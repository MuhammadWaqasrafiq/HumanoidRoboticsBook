<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-vla-models/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Chapter 10 - Vision-Language-Action Models | Embodied AI: The Future of Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/img/social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/img/social-card.jpg"><meta data-rh="true" property="og:url" content="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/docs/vla-models"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Chapter 10 - Vision-Language-Action Models | Embodied AI: The Future of Robotics"><meta data-rh="true" name="description" content="Master Vision-Language-Action (VLA) models for humanoid robot control - from OpenVLA basics to GR00T N1 deployment"><meta data-rh="true" property="og:description" content="Master Vision-Language-Action (VLA) models for humanoid robot control - from OpenVLA basics to GR00T N1 deployment"><meta data-rh="true" name="keywords" content="vla-models,vision-language-action,openvla,groot-n1,robot-learning,end-to-end-control,physical-intelligence"><link data-rh="true" rel="icon" href="/HumanoidRoboticsBook/img/new_logo.svg"><link data-rh="true" rel="canonical" href="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/docs/vla-models"><link data-rh="true" rel="alternate" href="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/docs/vla-models" hreflang="en"><link data-rh="true" rel="alternate" href="https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/docs/vla-models" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"10. Vision-Language-Action Models","item":"https://muhammadwaqasrafiq.github.io/HumanoidRoboticsBook/docs/vla-models/"}]}</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css"><link rel="stylesheet" href="/HumanoidRoboticsBook/assets/css/styles.a6d7e190.css">
<script src="/HumanoidRoboticsBook/assets/js/runtime~main.803ab506.js" defer="defer"></script>
<script src="/HumanoidRoboticsBook/assets/js/main.a5cf34ea.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||"light"),document.documentElement.setAttribute("data-theme-choice",t||"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/HumanoidRoboticsBook/"><div class="navbar__logo"><img src="/HumanoidRoboticsBook/img/new_logo.svg" alt="Embodied AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/HumanoidRoboticsBook/img/new_logo.svg" alt="Embodied AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Embodied AI</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/HumanoidRoboticsBook/docs/intro">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/HumanoidRoboticsBook/docs/intro"><span title="Introduction" class="linkLabel_WmDU">Introduction</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/HumanoidRoboticsBook/docs/why-physical-ai"><span title="Part I: Foundation" class="categoryLinkLabel_W154">Part I: Foundation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/why-physical-ai"><span title="01. Why Physical AI Is the Next Frontier" class="linkLabel_WmDU">01. Why Physical AI Is the Next Frontier</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/hardware-2026"><span title="02. The Hardware You Actually Need in 2026" class="linkLabel_WmDU">02. The Hardware You Actually Need in 2026</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/HumanoidRoboticsBook/docs/ros2-fundamentals"><span title="Part II: ROS 2 &amp; Simulation" class="categoryLinkLabel_W154">Part II: ROS 2 &amp; Simulation</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/HumanoidRoboticsBook/docs/ros2-fundamentals"><span title="03. ROS 2 – The Robotic Nervous System" class="categoryLinkLabel_W154">03. ROS 2 – The Robotic Nervous System</span></a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/urdf-digital-twins"><span title="04. URDF &amp; Digital Twins" class="linkLabel_WmDU">04. URDF &amp; Digital Twins</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/simulation-ecosystem"><span title="05. Gazebo vs Isaac Sim" class="linkLabel_WmDU">05. Gazebo vs Isaac Sim</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/isaac-platform"><span title="06. NVIDIA Isaac Platform" class="linkLabel_WmDU">06. NVIDIA Isaac Platform</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/HumanoidRoboticsBook/docs/perception-stack"><span title="Part III: Core Robotics" class="categoryLinkLabel_W154">Part III: Core Robotics</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/perception-stack"><span title="07. Perception Stack" class="linkLabel_WmDU">07. Perception Stack</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/bipedal-locomotion"><span title="08. Bipedal Locomotion" class="linkLabel_WmDU">08. Bipedal Locomotion</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/dexterous-manipulation"><span title="09. Dexterous Manipulation" class="linkLabel_WmDU">09. Dexterous Manipulation</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/HumanoidRoboticsBook/docs/vla-models"><span title="Part IV: Intelligence Layer" class="categoryLinkLabel_W154">Part IV: Intelligence Layer</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/HumanoidRoboticsBook/docs/vla-models"><span title="10. Vision-Language-Action Models" class="linkLabel_WmDU">10. Vision-Language-Action Models</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/voice-to-action"><span title="11. Voice-to-Action Pipeline" class="linkLabel_WmDU">11. Voice-to-Action Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/sim-to-real"><span title="12. Sim-to-Real Transfer" class="linkLabel_WmDU">12. Sim-to-Real Transfer</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/HumanoidRoboticsBook/docs/capstone-butler"><span title="Part V: Integration" class="categoryLinkLabel_W154">Part V: Integration</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/HumanoidRoboticsBook/docs/capstone-butler"><span title="13. Capstone: Autonomous Butler" class="linkLabel_WmDU">13. Capstone: Autonomous Butler</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/HumanoidRoboticsBook/docs/appendices/lab-build-guides"><span title="Appendices" class="categoryLinkLabel_W154">Appendices</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/HumanoidRoboticsBook/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Part IV: Intelligence Layer</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">10. Vision-Language-Action Models</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Chapter 10: Vision-Language-Action Models</h1></header>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Chapter Overview</div><div class="admonitionContent_BuS1"><p>Learn how Vision-Language-Action (VLA) models revolutionize robotics by directly mapping visual observations and natural language commands to robot actions - no manual programming required. Deploy state-of-the-art VLA models for humanoid control.</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-youll-learn">What You&#x27;ll Learn<a href="#what-youll-learn" class="hash-link" aria-label="Direct link to What You&#x27;ll Learn" title="Direct link to What You&#x27;ll Learn" translate="no">​</a></h2>
<p>By the end of this chapter, you&#x27;ll be able to:</p>
<ul>
<li class="">✅ Understand VLA architecture (vision encoders, language models, action decoders)</li>
<li class="">✅ Compare 7+ VLA models (OpenVLA, GR00T N1, Helix, π0, Octo, Gemini Robotics)</li>
<li class="">✅ Run OpenVLA-7B inference on RTX GPU (12 GB VRAM)</li>
<li class="">✅ Deploy GR00T N1 for humanoid locomotion and manipulation</li>
<li class="">✅ Optimize VLA models with 8-bit/4-bit quantization (reduce VRAM by 50-75%)</li>
<li class="">✅ Integrate VLA models with ROS 2 for real robot control</li>
<li class="">✅ Evaluate VLA performance (success rate, latency, generalization)</li>
<li class="">✅ Select appropriate VLA model for your use case</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<p>Before starting this chapter, you should:</p>
<ul>
<li class="">✅ Complete <strong><a class="" href="/HumanoidRoboticsBook/isaac-platform">Chapter 06: Isaac Platform</a></strong> (Isaac Sim fundamentals)</li>
<li class="">✅ Understand transformer architectures and attention mechanisms</li>
<li class="">✅ Have Python 3.10+ and PyTorch 2.0+ installed</li>
<li class="">✅ Have RTX GPU with 8+ GB VRAM (12 GB recommended)</li>
<li class="">✅ Familiarity with Hugging Face Transformers library</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Hardware Requirements</div><div class="admonitionContent_BuS1"><p><strong>Minimum:</strong> RTX 4060 Ti (16 GB VRAM) for OpenVLA-7B inference
<strong>Recommended:</strong> RTX 4070 Ti (12 GB) or RTX 4080 (16 GB) for fine-tuning
<strong>Professional:</strong> RTX 4090 (24 GB) or A100 (40 GB) for training from scratch</p></div></div>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-vla-models-matter">Why VLA Models Matter<a href="#why-vla-models-matter" class="hash-link" aria-label="Direct link to Why VLA Models Matter" title="Direct link to Why VLA Models Matter" translate="no">​</a></h2>
<p>Traditional robot control requires <strong>weeks of manual engineering</strong> per task:</p>
<ol>
<li class="">Train object detector (YOLOv8, Faster R-CNN)</li>
<li class="">Write grasp planner (heuristics, learned grasping networks)</li>
<li class="">Code motion controller (inverse kinematics, trajectory optimization)</li>
<li class="">Debug integration issues (coordinate frames, timing, edge cases)</li>
</ol>
<p><strong>VLA models replace this entire pipeline with a single end-to-end model trained on demonstrations.</strong></p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="traditional-vs-vla-approach">Traditional vs. VLA Approach<a href="#traditional-vs-vla-approach" class="hash-link" aria-label="Direct link to Traditional vs. VLA Approach" title="Direct link to Traditional vs. VLA Approach" translate="no">​</a></h3>
<table><thead><tr><th>Aspect</th><th>Traditional Pipeline</th><th>VLA Approach</th></tr></thead><tbody><tr><td><strong>Development Time</strong></td><td>Weeks per task</td><td>Hours with fine-tuning</td></tr><tr><td><strong>Components</strong></td><td>3-5 separate modules</td><td>Single end-to-end model</td></tr><tr><td><strong>Generalization</strong></td><td>Brittle to new objects/scenes</td><td>Robust to novel situations</td></tr><tr><td><strong>Required Expertise</strong></td><td>Robotics PhD-level</td><td>Demonstration collection</td></tr><tr><td><strong>Typical Success Rate</strong></td><td>60-80% (task-specific)</td><td>70-90% (generalist)</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-architecture-fundamentals">VLA Architecture Fundamentals<a href="#vla-architecture-fundamentals" class="hash-link" aria-label="Direct link to VLA Architecture Fundamentals" title="Direct link to VLA Architecture Fundamentals" translate="no">​</a></h2>
<p>All VLA models share a common three-component architecture:</p>
<!-- -->
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="component-breakdown">Component Breakdown<a href="#component-breakdown" class="hash-link" aria-label="Direct link to Component Breakdown" title="Direct link to Component Breakdown" translate="no">​</a></h3>
<p><strong>1. Vision Encoder</strong> (extracts visual features from robot camera)</p>
<ul>
<li class=""><strong>DINOv2</strong> (Meta AI): Self-supervised ViT, excellent for robotics</li>
<li class=""><strong>SigLIP</strong> (Google): Language-aligned vision encoder</li>
<li class=""><strong>Input:</strong> 224x224 RGB image → <strong>Output:</strong> 768-1024D feature vector</li>
</ul>
<p><strong>2. Language Model</strong> (understands natural language commands)</p>
<ul>
<li class=""><strong>Llama 2</strong> (7B-70B params): Strong reasoning, open-source</li>
<li class=""><strong>Gemma</strong> (2B-7B params): Efficient, fast inference</li>
<li class=""><strong>Input:</strong> Text string → <strong>Output:</strong> Contextualized embeddings</li>
</ul>
<p><strong>3. Fusion Layer</strong> (combines vision + language)</p>
<ul>
<li class=""><strong>Cross-attention:</strong> Vision attends to language tokens</li>
<li class=""><strong>Gated fusion:</strong> Learned importance weights for each modality</li>
</ul>
<p><strong>4. Action Decoder</strong> (generates robot control commands)</p>
<ul>
<li class=""><strong>MLP:</strong> Fast (8-12 Hz), deterministic</li>
<li class=""><strong>Diffusion:</strong> Smooth (10-20 Hz), handles multi-modality</li>
<li class=""><strong>Flow Matching:</strong> Fastest + smoothest (50-120 Hz), used by π0 and GR00T N1</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="openvla-your-first-vla-model">OpenVLA: Your First VLA Model<a href="#openvla-your-first-vla-model" class="hash-link" aria-label="Direct link to OpenVLA: Your First VLA Model" title="Direct link to OpenVLA: Your First VLA Model" translate="no">​</a></h2>
<p><strong>OpenVLA</strong> is the ideal starting point for learning VLAs:</p>
<p>✅ <strong>Open-source</strong> (MIT license) - weights, code, data all public
✅ <strong>Strong performance</strong> - Outperforms RT-2-X (55B) with only 7B parameters (+16.5% success rate)
✅ <strong>Well-documented</strong> - Hugging Face Hub, tutorials, active community
✅ <strong>Reproducible</strong> - Easy setup, no proprietary dependencies</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="openvla-architecture">OpenVLA Architecture<a href="#openvla-architecture" class="hash-link" aria-label="Direct link to OpenVLA Architecture" title="Direct link to OpenVLA Architecture" translate="no">​</a></h3>
<p><strong>OpenVLA-7B</strong> uses a dual vision encoder approach:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Simplified architecture</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">vision_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cat</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    dinov2_encoder</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Object-centric features</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    siglip_encoder</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">image</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">   </span><span class="token comment" style="color:#999988;font-style:italic"># Language-aligned features</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> dim</span><span class="token operator" style="color:#393A34">=</span><span class="token operator" style="color:#393A34">-</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">language_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> llama2_7b</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">text_command</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">fused_features </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> cross_attention</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">vision_features</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> language_features</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">actions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> mlp_head</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">fused_features</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 7-DoF action vector</span><br></span></code></pre></div></div>
<p><strong>Key Specifications:</strong></p>
<ul>
<li class=""><strong>Parameters:</strong> 7.23 billion</li>
<li class=""><strong>Vision:</strong> DINOv2-Base + SigLIP-Base (dual encoders)</li>
<li class=""><strong>Language:</strong> Llama 2-7B</li>
<li class=""><strong>Action Space:</strong> 7-DoF (6 joints + gripper)</li>
<li class=""><strong>Inference Speed:</strong> 80-120ms per action (8-12 Hz)</li>
<li class=""><strong>VRAM (FP16):</strong> 14 GB | <strong>VRAM (INT8):</strong> 7 GB</li>
<li class=""><strong>Training Data:</strong> 970,000 robot trajectories (Open X-Embodiment dataset)</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="installation-and-setup">Installation and Setup<a href="#installation-and-setup" class="hash-link" aria-label="Direct link to Installation and Setup" title="Direct link to Installation and Setup" translate="no">​</a></h3>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-1-install-dependencies">Step 1: Install Dependencies<a href="#step-1-install-dependencies" class="hash-link" aria-label="Direct link to Step 1: Install Dependencies" title="Direct link to Step 1: Install Dependencies" translate="no">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Create virtual environment</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python3.10 </span><span class="token parameter variable" style="color:#36acaa">-m</span><span class="token plain"> venv openvla_env</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">source</span><span class="token plain"> openvla_env/bin/activate  </span><span class="token comment" style="color:#999988;font-style:italic"># Windows: openvla_env\Scripts\activate</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Install PyTorch with CUDA 12.1</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> torch torchvision --index-url https://download.pytorch.org/whl/cu121</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Install Transformers and quantization libraries</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> transformers accelerate bitsandbytes pillow numpy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Install OpenVLA (from source for latest features)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/openvla/openvla.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> openvla</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip </span><span class="token function" style="color:#d73a49">install</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-e</span><span class="token plain"> </span><span class="token builtin class-name">.</span><br></span></code></pre></div></div>
<h4 class="anchor anchorTargetStickyNavbar_Vzrq" id="step-2-test-installation">Step 2: Test Installation<a href="#step-2-test-installation" class="hash-link" aria-label="Direct link to Step 2: Test Installation" title="Direct link to Step 2: Test Installation" translate="no">​</a></h4>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoProcessor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load model (downloads ~14 GB on first run)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">processor </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoProcessor</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;openvla/openvla-7b&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> trust_remote_code</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;openvla/openvla-7b&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch_dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;float16&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device_map</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;auto&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    trust_remote_code</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;✅ OpenVLA-7B loaded successfully!&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;   Parameters: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation builtin">sum</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation">p</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">numel</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation keyword" style="color:#00009f">for</span><span class="token string-interpolation interpolation"> p </span><span class="token string-interpolation interpolation keyword" style="color:#00009f">in</span><span class="token string-interpolation interpolation"> model</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">parameters</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">(</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">)</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation operator" style="color:#393A34">/</span><span class="token string-interpolation interpolation"> </span><span class="token string-interpolation interpolation number" style="color:#36acaa">1e9</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">B&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;   Device: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">model</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">.</span><span class="token string-interpolation interpolation">device</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><strong>Expected output:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">✅ OpenVLA-7B loaded successfully!</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Parameters: 7.23B</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Device: cuda:0</span><br></span></code></pre></div></div>
<hr>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="basic-inference-example">Basic Inference Example<a href="#basic-inference-example" class="hash-link" aria-label="Direct link to Basic Inference Example" title="Direct link to Basic Inference Example" translate="no">​</a></h3>
<p>Create <code>code-examples/vla/openvla_inference.py</code>:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic">#!/usr/bin/env python3</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">OpenVLA-7B Basic Inference</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">Demonstrates image + text → robot actions</span><br></span><span class="token-line" style="color:#393A34"><span class="token triple-quoted-string string" style="color:#e3116c">&quot;&quot;&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> AutoProcessor</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> PIL </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> Image</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> numpy </span><span class="token keyword" style="color:#00009f">as</span><span class="token plain"> np</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Initialize model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">device </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;cuda&quot;</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">cuda</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">is_available</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">else</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;cpu&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;Using device: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">device</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">processor </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoProcessor</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;openvla/openvla-7b&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> trust_remote_code</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;openvla/openvla-7b&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    torch_dtype</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">float16</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device_map</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;auto&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    trust_remote_code</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load robot camera image</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">image </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Image</span><span class="token punctuation" style="color:#393A34">.</span><span class="token builtin">open</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;robot_camera.jpg&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># 224x224 RGB recommended</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">instruction </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;pick up the red cup and place it on the table&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Prepare inputs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">inputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> processor</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">text</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">instruction</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> images</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">image</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> return_tensors</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;pt&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">to</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">device</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Run inference</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">no_grad</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    outputs </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">generate</span><span class="token punctuation" style="color:#393A34">(</span><span class="token operator" style="color:#393A34">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> max_new_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">512</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> do_sample</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">False</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Decode actions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">action_str </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> processor</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">decode</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">outputs</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> skip_special_tokens</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">actions </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">array</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">[</span><span class="token builtin">float</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">x</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">for</span><span class="token plain"> x </span><span class="token keyword" style="color:#00009f">in</span><span class="token plain"> action_str</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">split</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;,&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;\n📸 Image: robot_camera.jpg&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;💬 Command: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">instruction</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;🤖 Actions: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">actions</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;   Joints (6 DoF): </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">actions</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">[</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">:</span><span class="token string-interpolation interpolation format-spec">6]</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c">&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;   Gripper: </span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">{</span><span class="token string-interpolation interpolation">actions</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">[</span><span class="token string-interpolation interpolation number" style="color:#36acaa">6</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">]</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">:</span><span class="token string-interpolation interpolation format-spec">.2f</span><span class="token string-interpolation interpolation punctuation" style="color:#393A34">}</span><span class="token string-interpolation string" style="color:#e3116c"> (0=open, 1=closed)&quot;</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre></div></div>
<p><strong>Run:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">python code-examples/vla/openvla_inference.py</span><br></span></code></pre></div></div>
<p><strong>Example output:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Using device: cuda</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">📸 Image: robot_camera.jpg</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">💬 Command: pick up the red cup and place it on the table</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">🤖 Actions: [ 0.45  0.23 -0.12  1.57  0.34 -0.21  1.00]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Joints (6 DoF): [ 0.45  0.23 -0.12  1.57  0.34 -0.21]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   Gripper: 1.00 (0=open, 1=closed)</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="model-quantization-reduce-vram-by-50-75">Model Quantization (Reduce VRAM by 50-75%)<a href="#model-quantization-reduce-vram-by-50-75" class="hash-link" aria-label="Direct link to Model Quantization (Reduce VRAM by 50-75%)" title="Direct link to Model Quantization (Reduce VRAM by 50-75%)" translate="no">​</a></h2>
<p><strong>Problem:</strong> OpenVLA-7B requires 14 GB VRAM (FP16), but most consumer GPUs have 8-12 GB.</p>
<p><strong>Solution:</strong> Quantization - reduce precision from FP16 to INT8 or INT4.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="quantization-trade-offs">Quantization Trade-offs<a href="#quantization-trade-offs" class="hash-link" aria-label="Direct link to Quantization Trade-offs" title="Direct link to Quantization Trade-offs" translate="no">​</a></h3>
<table><thead><tr><th>Precision</th><th>VRAM</th><th>Speed</th><th>Accuracy Loss</th><th>Recommended For</th></tr></thead><tbody><tr><td>FP16 (baseline)</td><td>14 GB</td><td>1x</td><td>0%</td><td>RTX 4080+</td></tr><tr><td>INT8 (8-bit)</td><td>7 GB</td><td>1.5-2x</td><td>&lt;1%</td><td><strong>RTX 4060 Ti+</strong></td></tr><tr><td>INT4 (4-bit)</td><td>3.5 GB</td><td>2-3x</td><td>2-3%</td><td>RTX 3060 (experiments)</td></tr></tbody></table>
<p><strong>Recommendation:</strong> INT8 for production - minimal accuracy loss, 2x VRAM reduction.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="int8-quantization-with-bitsandbytes">INT8 Quantization with bitsandbytes<a href="#int8-quantization-with-bitsandbytes" class="hash-link" aria-label="Direct link to INT8 Quantization with bitsandbytes" title="Direct link to INT8 Quantization with bitsandbytes" translate="no">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> BitsAndBytesConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Configure 8-bit quantization</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">quant_config </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> BitsAndBytesConfig</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    load_in_8bit</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llm_int8_threshold</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">6.0</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># Outlier detection</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load quantized model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForVision2Seq</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;openvla/openvla-7b&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    quantization_config</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">quant_config</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    device_map</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;auto&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    trust_remote_code</span><span class="token operator" style="color:#393A34">=</span><span class="token boolean" style="color:#36acaa">True</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;✅ Model loaded in INT8&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">print</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string-interpolation string" style="color:#e3116c">f&quot;   VRAM: ~7 GB (50% reduction from FP16)&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Inference works identically!</span><br></span></code></pre></div></div>
<p><strong>Accuracy benchmarks:</strong></p>
<ul>
<li class=""><strong>FP16:</strong> 72.1% task success rate</li>
<li class=""><strong>INT8:</strong> 71.6% success rate (-0.5%, negligible)</li>
<li class=""><strong>INT4:</strong> 69.8% success rate (-2.3%, acceptable for experimentation)</li>
</ul>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ros-2-integration">ROS 2 Integration<a href="#ros-2-integration" class="hash-link" aria-label="Direct link to ROS 2 Integration" title="Direct link to ROS 2 Integration" translate="no">​</a></h2>
<p>Integrate OpenVLA with ROS 2 for real robot control. See <code>code-examples/vla/openvla_ros2_node.py</code> (created separately).</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="gr00t-n1-humanoid-specific-vla">GR00T N1: Humanoid-Specific VLA<a href="#gr00t-n1-humanoid-specific-vla" class="hash-link" aria-label="Direct link to GR00T N1: Humanoid-Specific VLA" title="Direct link to GR00T N1: Humanoid-Specific VLA" translate="no">​</a></h2>
<p><strong>NVIDIA GR00T N1</strong> is the first open VLA specifically designed for humanoid robots.</p>
<p><strong>Why GR00T N1 for humanoids:</strong></p>
<ul>
<li class="">✅ <strong>Dual-system architecture:</strong> System 1 (120Hz motor control) + System 2 (VLM planning)</li>
<li class="">✅ <strong>Humanoid-specific training:</strong> Data from bipedal robots (Fourier GR-1, 1X NEO)</li>
<li class="">✅ <strong>Open foundation model:</strong> Fully customizable, no licensing restrictions</li>
<li class="">✅ <strong>Isaac Sim integration:</strong> Seamless workflow with Chapter 06</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="gr00t-n1-architecture">GR00T N1 Architecture<a href="#gr00t-n1-architecture" class="hash-link" aria-label="Direct link to GR00T N1 Architecture" title="Direct link to GR00T N1 Architecture" translate="no">​</a></h3>
<!-- -->
<p><strong>Key Innovation:</strong> <strong>Separation of concerns</strong></p>
<ul>
<li class=""><strong>System 2 (slow):</strong> Reasons about task, generates plan (1-2 Hz)</li>
<li class=""><strong>System 1 (fast):</strong> Executes plan with reactive motor control (120 Hz)</li>
</ul>
<p>This matches human cognition: <strong>deliberate planning + reactive execution</strong>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-model-comparison">VLA Model Comparison<a href="#vla-model-comparison" class="hash-link" aria-label="Direct link to VLA Model Comparison" title="Direct link to VLA Model Comparison" translate="no">​</a></h2>
<p>Based on research from <code>specs/001-physical-ai-book/research.md</code>, here&#x27;s a practical comparison:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="quick-selection-guide">Quick Selection Guide<a href="#quick-selection-guide" class="hash-link" aria-label="Direct link to Quick Selection Guide" title="Direct link to Quick Selection Guide" translate="no">​</a></h3>
<p><strong>Choose OpenVLA if:</strong></p>
<ul>
<li class="">✅ Learning VLAs for the first time</li>
<li class="">✅ Need reproducible research baseline</li>
<li class="">✅ Have RTX 4070 Ti (12 GB VRAM)</li>
<li class="">✅ Want Hugging Face integration</li>
</ul>
<p><strong>Choose GR00T N1 if:</strong></p>
<ul>
<li class="">✅ Building humanoid robot application</li>
<li class="">✅ Using NVIDIA Isaac Sim ecosystem</li>
<li class="">✅ Need 120Hz real-time control</li>
<li class="">✅ Want dual-system architecture</li>
</ul>
<p><strong>Choose π0/π0.5 if:</strong></p>
<ul>
<li class="">✅ Need smooth flow-matching trajectories (50 Hz)</li>
<li class="">✅ Mobile manipulator application</li>
<li class="">✅ Want open-world generalization</li>
<li class="">✅ Have 6-8 GB VRAM (efficient)</li>
</ul>
<p><strong>Choose Octo if:</strong></p>
<ul>
<li class="">✅ Transfer learning across robot types</li>
<li class="">✅ Fast fine-tuning (hours on consumer GPU)</li>
<li class="">✅ Goal-conditioned tasks (image goals)</li>
<li class="">✅ Research on embodiment adaptation</li>
</ul>
<p>For full comparison tables (hardware requirements, licensing, performance benchmarks), see <code>specs/001-physical-ai-book/research.md</code>.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">​</a></h2>
<ol>
<li class=""><strong>VLA models are the future of robot control</strong> - end-to-end learning eliminates weeks of manual engineering</li>
<li class=""><strong>OpenVLA is the best starting point</strong> - open-source, well-documented, strong performance</li>
<li class=""><strong>Quantization is essential</strong> - INT8 reduces VRAM by 50% with &lt;1% accuracy loss</li>
<li class=""><strong>GR00T N1 for humanoids</strong> - dual-system architecture designed for bipedal robots</li>
<li class=""><strong>Model selection matters</strong> - choose based on use case (education vs production, humanoid vs manipulation)</li>
</ol>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">​</a></h2>
<ul>
<li class=""><strong>Practice:</strong> Run OpenVLA inference examples in <code>code-examples/vla/</code></li>
<li class=""><strong>Experiment:</strong> Test different quantization levels (INT8 vs INT4)</li>
<li class=""><strong>Integrate:</strong> Connect OpenVLA to your ROS 2 robot (real or simulated)</li>
<li class=""><strong>Advanced:</strong> Explore fine-tuning OpenVLA on custom tasks (50-100 demos)</li>
<li class=""><strong>Production:</strong> Deploy GR00T N1 for humanoid applications with Isaac Sim</li>
</ul>
<p>Continue to <a class="" href="/HumanoidRoboticsBook/voice-to-action">Chapter 11: Voice-to-Action Pipeline</a> to add speech recognition and complete the end-to-end system!</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook/tree/main/docs/vla-models/index.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/HumanoidRoboticsBook/docs/dexterous-manipulation"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">09. Dexterous Manipulation</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/HumanoidRoboticsBook/docs/voice-to-action"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">11. Voice-to-Action Pipeline</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-youll-learn" class="table-of-contents__link toc-highlight">What You&#39;ll Learn</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#why-vla-models-matter" class="table-of-contents__link toc-highlight">Why VLA Models Matter</a><ul><li><a href="#traditional-vs-vla-approach" class="table-of-contents__link toc-highlight">Traditional vs. VLA Approach</a></li></ul></li><li><a href="#vla-architecture-fundamentals" class="table-of-contents__link toc-highlight">VLA Architecture Fundamentals</a><ul><li><a href="#component-breakdown" class="table-of-contents__link toc-highlight">Component Breakdown</a></li></ul></li><li><a href="#openvla-your-first-vla-model" class="table-of-contents__link toc-highlight">OpenVLA: Your First VLA Model</a><ul><li><a href="#openvla-architecture" class="table-of-contents__link toc-highlight">OpenVLA Architecture</a></li><li><a href="#installation-and-setup" class="table-of-contents__link toc-highlight">Installation and Setup</a></li><li><a href="#basic-inference-example" class="table-of-contents__link toc-highlight">Basic Inference Example</a></li></ul></li><li><a href="#model-quantization-reduce-vram-by-50-75" class="table-of-contents__link toc-highlight">Model Quantization (Reduce VRAM by 50-75%)</a><ul><li><a href="#quantization-trade-offs" class="table-of-contents__link toc-highlight">Quantization Trade-offs</a></li><li><a href="#int8-quantization-with-bitsandbytes" class="table-of-contents__link toc-highlight">INT8 Quantization with bitsandbytes</a></li></ul></li><li><a href="#ros-2-integration" class="table-of-contents__link toc-highlight">ROS 2 Integration</a></li><li><a href="#gr00t-n1-humanoid-specific-vla" class="table-of-contents__link toc-highlight">GR00T N1: Humanoid-Specific VLA</a><ul><li><a href="#gr00t-n1-architecture" class="table-of-contents__link toc-highlight">GR00T N1 Architecture</a></li></ul></li><li><a href="#vla-model-comparison" class="table-of-contents__link toc-highlight">VLA Model Comparison</a><ul><li><a href="#quick-selection-guide" class="table-of-contents__link toc-highlight">Quick Selection Guide</a></li></ul></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Learn</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/HumanoidRoboticsBook/docs/intro">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/HumanoidRoboticsBook/docs/why-physical-ai">Why Physical AI</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Repo<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook/tree/main/code-examples" target="_blank" rel="noopener noreferrer" class="footer__link-item">Code Samples<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Connect</div><ul class="footer__items clean-list"><li class="footer__item">
<div style="display:flex; gap:1.5rem; margin-bottom:1rem;">
  <a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook" target="_blank" rel="noopener noreferrer" aria-label="GitHub" style="color:#fff;font-size:1.6rem;">
    <i class="fa-brands fa-github"></i>
  </a>
  <a href="https://linkedin.com/in/MuhammadWaqasrafiq" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn" style="color:#fff;font-size:1.6rem;">
    <i class="fa-brands fa-linkedin"></i>
  </a>
  <a href="https://wa.me/923463033195" target="_blank" rel="noopener noreferrer" aria-label="WhatsApp" style="color:#fff;font-size:1.6rem;">
    <i class="fa-brands fa-whatsapp"></i>
  </a>
  <a href="https://www.youtube.com/watch?v=dZTfXiPSZyE" target="_blank" rel="noopener noreferrer" aria-label="YouTube" style="color:#fff;font-size:1.6rem;">
    <i class="fa-brands fa-youtube"></i>
  </a>
</div>
              </li><li class="footer__item"><a href="https://github.com/MuhammadWaqasrafiq/HumanoidRoboticsBook/blob/main/LICENSE" target="_blank" rel="noopener noreferrer" class="footer__link-item">MIT License<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">© 2025 Embodied AI • Muhammad Waqas Rafiq • MIT & CC-BY-4.0</div></div></div></footer></div>
</body>
</html>